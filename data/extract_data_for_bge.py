#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æŠ½å–è„šæœ¬ - ç”¨äºåœ¨æœ‰SSMSçš„ç”µè„‘ä¸Šè¿è¡Œ
æŠ½å–ESGæ•°æ®å¹¶ç”ŸæˆCSVæ–‡ä»¶ï¼Œå¸¦å›è¿›è¡ŒBGE embedding
"""

import os
import pandas as pd
import pyodbc
from datetime import datetime

def extract_esg_data():
    """æŠ½å–ESGæ•°æ®å¹¶ä¿å­˜ä¸ºCSVæ–‡ä»¶"""
    print("ğŸš€ ESGæ•°æ®æŠ½å–è„šæœ¬")
    print("=" * 50)
    
    try:
        # 1. è¿æ¥SQL Server
        print("ğŸ”Œ è¿æ¥SQL Server...")
        CNSTR = r"DRIVER={ODBC Driver 17 for SQL Server};SERVER=localhost;DATABASE=ESG;Trusted_Connection=yes;"
        cn = pyodbc.connect(CNSTR, autocommit=True)
        print("âœ… SQL Serverè¿æ¥æˆåŠŸ")
        
        # 2. æ£€æŸ¥æ•°æ®é‡
        print("ğŸ“Š æ£€æŸ¥æ•°æ®é‡...")
        total_count = pd.read_sql("SELECT COUNT(*) FROM dbo.fact_observation WHERE (value_numeric IS NOT NULL OR value_text IS NOT NULL)", cn).iloc[0, 0]
        print(f"ğŸ“ˆ æ€»è®°å½•æ•°: {total_count}")
        
        # 3. æŠ½å–ç»´åº¦è¡¨æ•°æ®
        print("ğŸ“‹ æŠ½å–ç»´åº¦è¡¨æ•°æ®...")
        
        # å…¬å¸ç»´åº¦è¡¨
        print("   ğŸ“Š æŠ½å–å…¬å¸ç»´åº¦è¡¨...")
        dim_company = pd.read_sql("SELECT ticker, company_name FROM dbo.dim_company ORDER BY ticker", cn)
        print(f"   âœ… å…¬å¸ç»´åº¦è¡¨: {len(dim_company)} æ¡è®°å½•")
        
        # å­—æ®µç»´åº¦è¡¨
        print("   ğŸ“Š æŠ½å–å­—æ®µç»´åº¦è¡¨...")
        dim_field = pd.read_sql("SELECT field_code, field_name, esg_bucket FROM dbo.dim_field ORDER BY field_code", cn)
        print(f"   âœ… å­—æ®µç»´åº¦è¡¨: {len(dim_field)} æ¡è®°å½•")
        
        # 4. æŠ½å–äº‹å®è¡¨æ•°æ®
        print("ğŸ“Š æŠ½å–äº‹å®è¡¨æ•°æ®...")
        
        # åˆ†æ‰¹æŠ½å–ï¼Œé¿å…å†…å­˜é—®é¢˜
        batch_size = 10000
        all_facts = []
        
        sql_facts = """
        SELECT 
            f.ticker, 
            f.[year], 
            f.field_code,
            COALESCE(CAST(f.value_numeric AS varchar(100)), f.value_text) AS val,
            f.incomplete, 
            f.source_file,
            d.field_name, 
            d.esg_bucket, 
            c.company_name
        FROM dbo.fact_observation f
        JOIN dbo.dim_field d ON d.field_code = f.field_code
        JOIN dbo.dim_company c ON c.ticker = f.ticker
        WHERE (f.value_numeric IS NOT NULL OR f.value_text IS NOT NULL)
        ORDER BY f.ticker, f.[year], d.field_code
        """
        
        print("   ğŸ“¥ å¼€å§‹åˆ†æ‰¹æŠ½å–äº‹å®æ•°æ®...")
        offset = 0
        
        while True:
            sql_batch = f"""
            {sql_facts}
            OFFSET {offset} ROWS
            FETCH NEXT {batch_size} ROWS ONLY
            """
            
            batch_df = pd.read_sql(sql_batch, cn)
            
            if batch_df.empty:
                break
                
            all_facts.append(batch_df)
            offset += batch_size
            
            print(f"   ğŸ“Š å·²æŠ½å– {offset} æ¡è®°å½•...")
            
            if len(batch_df) < batch_size:
                break
        
        # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡
        if all_facts:
            facts = pd.concat(all_facts, ignore_index=True)
            print(f"   âœ… äº‹å®è¡¨æ•°æ®: {len(facts)} æ¡è®°å½•")
        else:
            print("   âŒ æ²¡æœ‰æŠ½å–åˆ°äº‹å®æ•°æ®")
            return
        
        # 5. åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "esg_data_export"
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
        
        # 6. ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶
        print("ğŸ’¾ ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶...")
        
        # ä¿å­˜ç»´åº¦è¡¨
        dim_company.to_csv(os.path.join(output_dir, "dim_company.csv"), index=False, encoding='utf-8-sig')
        dim_field.to_csv(os.path.join(output_dir, "dim_field.csv"), index=False, encoding='utf-8-sig')
        
        # ä¿å­˜äº‹å®è¡¨
        facts.to_csv(os.path.join(output_dir, "fact_observation.csv"), index=False, encoding='utf-8-sig')
        
        # 7. ç”Ÿæˆæ•°æ®æ‘˜è¦
        print("ğŸ“‹ ç”Ÿæˆæ•°æ®æ‘˜è¦...")
        
        summary = {
            "extraction_time": datetime.now().isoformat(),
            "total_companies": len(dim_company),
            "total_fields": len(dim_field),
            "total_facts": len(facts),
            "year_range": f"{facts['year'].min()}-{facts['year'].max()}",
            "companies_sample": dim_company['ticker'].head(10).tolist(),
            "fields_sample": dim_field['field_code'].head(10).tolist()
        }
        
        # ä¿å­˜æ‘˜è¦
        import json
        with open(os.path.join(output_dir, "data_summary.json"), 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        # 8. ç”Ÿæˆç”¨äºBGE embeddingçš„æ–‡æœ¬æ•°æ®
        print("ğŸ“ ç”ŸæˆBGE embeddingæ–‡æœ¬æ•°æ®...")
        
        def make_bge_text(r):
            """ç”ŸæˆBGE embeddingç”¨çš„æ–‡æœ¬"""
            return f"Company: {r.company_name} (Ticker: {r.ticker}) in {int(r.year)}: {r.field_name} (Code: {r.field_code}) = {r.val}"
        
        facts['bge_text'] = facts.apply(make_bge_text, axis=1)
        facts['id'] = facts.apply(lambda r: f"{r.ticker}_{int(r.year)}_{r.field_code}", axis=1)
        
        # ä¿å­˜BGEæ–‡æœ¬æ•°æ®
        bge_data = facts[['id', 'bge_text', 'ticker', 'company_name', 'year', 'field_code', 'field_name', 'value', 'esg_bucket']].copy()
        bge_data.to_csv(os.path.join(output_dir, "bge_embedding_data.csv"), index=False, encoding='utf-8-sig')
        
        print(f"âœ… BGEæ–‡æœ¬æ•°æ®: {len(bge_data)} æ¡è®°å½•")
        
        # 9. è¾“å‡ºå®Œæˆä¿¡æ¯
        print(f"\nğŸ‰ æ•°æ®æŠ½å–å®Œæˆï¼")
        print("=" * 50)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {os.path.abspath(output_dir)}")
        print(f"ğŸ“Š æ–‡ä»¶åˆ—è¡¨:")
        print(f"   - dim_company.csv ({len(dim_company)} æ¡)")
        print(f"   - dim_field.csv ({len(dim_field)} æ¡)")
        print(f"   - fact_observation.csv ({len(facts)} æ¡)")
        print(f"   - bge_embedding_data.csv ({len(bge_data)} æ¡)")
        print(f"   - data_summary.json")
        
        print(f"\nğŸ“‹ æ•°æ®æ‘˜è¦:")
        print(f"   - å…¬å¸æ•°é‡: {len(dim_company)}")
        print(f"   - å­—æ®µæ•°é‡: {len(dim_field)}")
        print(f"   - äº‹å®è®°å½•: {len(facts)}")
        print(f"   - å¹´ä»½èŒƒå›´: {facts['year'].min()}-{facts['year'].max()}")
        
        print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print(f"1. å°† {output_dir} æ–‡ä»¶å¤¹å¤åˆ¶åˆ°ç›®æ ‡ç”µè„‘")
        print(f"2. è¿è¡Œ build_bge_from_csv.py è¿›è¡Œembedding")
        print(f"3. ä½¿ç”¨æ–°çš„Chromaæ•°æ®åº“")
        
        # 10. ç”ŸæˆBGEæ„å»ºè„šæœ¬
        print(f"\nğŸ”§ ç”ŸæˆBGEæ„å»ºè„šæœ¬...")
        generate_bge_build_script(output_dir)
        
    except Exception as e:
        print(f"âŒ æŠ½å–å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

def generate_bge_build_script(output_dir):
    """ç”ŸæˆBGEæ„å»ºè„šæœ¬"""
    script_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»CSVæ–‡ä»¶æ„å»ºBGE-M3æ•°æ®åº“
"""

import os
import pandas as pd
import chromadb
from sentence_transformers import SentenceTransformer

def build_bge_from_csv():
    print("ğŸš€ ä»CSVæ–‡ä»¶æ„å»ºBGE-M3æ•°æ®åº“")
    print("=" * 50)
    
    try:
        # 1. åŠ è½½BGE-M3æ¨¡å‹
        print("ğŸ“¥ åŠ è½½BGE-M3æ¨¡å‹...")
        MODEL_NAME = "BAAI/bge-m3"
        model = SentenceTransformer(MODEL_NAME)
        print("âœ… BGE-M3æ¨¡å‹åŠ è½½å®Œæˆ")
        
        # 2. è¯»å–CSVæ•°æ®
        print("ğŸ“Š è¯»å–CSVæ•°æ®...")
        data_file = "bge_embedding_data.csv"
        
        if not os.path.exists(data_file):
            print(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {data_file}")
            return
        
        df = pd.read_csv(data_file, encoding='utf-8-sig')
        print(f"âœ… è¯»å–åˆ° {len(df)} æ¡è®°å½•")
        
        # 3. ç”Ÿæˆembedding
        print("ğŸ”¬ ç”ŸæˆBGE-M3 embedding...")
        texts = df['bge_text'].tolist()
        embs = model.encode(texts, normalize_embeddings=True, show_progress_bar=True)
        print(f"âœ… ç”Ÿæˆ {len(embs)} ä¸ªembedding")
        
        # 4. åˆ›å»ºChromaæ•°æ®åº“
        print("ğŸ’¾ åˆ›å»ºChromaæ•°æ®åº“...")
        db_path = "esg_chroma_bge_m3_final"
        
        if os.path.exists(db_path):
            import shutil
            shutil.rmtree(db_path)
            print(f"ğŸ—‘ï¸ åˆ é™¤æ—§æ•°æ®åº“")
        
        client = chromadb.PersistentClient(path=db_path)
        collection = client.create_collection(
            name="esg_bge_m3_final",
            metadata={
                "hnsw:space": "cosine",
                "model": MODEL_NAME,
                "version": "m3_final",
                "multilingual": True
            }
        )
        print(f"âœ… åˆ›å»ºæ•°æ®åº“: {db_path}")
        
        # 5. æ·»åŠ æ•°æ®
        print("ğŸ’¾ æ·»åŠ æ•°æ®åˆ°Chroma...")
        metadatas = []
        for _, row in df.iterrows():
            metadatas.append({
                "ticker": str(row['ticker']).strip(),
                "company": row['company_name'],
                "year": int(row['year']),
                "bucket": row['esg_bucket'] or "",
                "field_code": row['field_code'],
                "field_name": row['field_name'],
                "value": row['value']
            })
        
        collection.add(
            ids=df['id'].tolist(),
            embeddings=embs.tolist(),
            documents=df['bge_text'].tolist(),
            metadatas=metadatas
        )
        
        print(f"âœ… æˆåŠŸæ·»åŠ  {len(df)} æ¡è®°å½•")
        
        # 6. æµ‹è¯•æŸ¥è¯¢
        print("ğŸ§ª æµ‹è¯•æŸ¥è¯¢...")
        test_query = "A US Equity 2015å¹´å¥³æ€§å‘˜å·¥æ¯”ä¾‹"
        query_embedding = model.encode([test_query])[0].tolist()
        
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=3,
            include=['documents', 'metadatas', 'distances']
        )
        
        print(f"ğŸ” æµ‹è¯•æŸ¥è¯¢: {test_query}")
        for i, (doc, meta, dist) in enumerate(zip(results['documents'][0], results['metadatas'][0], results['distances'][0])):
            similarity = 1 - dist
            print(f"  {i+1}. ç›¸ä¼¼åº¦: {similarity:.3f}")
            print(f"     å…¬å¸: {meta.get('company', 'N/A')}")
            print(f"     è‚¡ç¥¨ä»£ç : {meta.get('ticker', 'N/A')}")
            print(f"     å¹´ä»½: {meta.get('year', 'N/A')}")
            print(f"     æŒ‡æ ‡: {meta.get('field_name', 'N/A')}")
        
        print(f"\\nğŸ‰ BGE-M3æ„å»ºå®Œæˆï¼")
        print(f"ğŸ“Š æ•°æ®åº“è·¯å¾„: {os.path.abspath(db_path)}")
        print(f"ğŸ“Š é›†åˆåç§°: esg_bge_m3_final")
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
        print(f"ğŸ“ˆ æ€»è®°å½•æ•°: {collection.count()}")
        
    except Exception as e:
        print(f"âŒ æ„å»ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    build_bge_from_csv()
'''
    
    script_path = os.path.join(output_dir, "build_bge_from_csv.py")
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"âœ… ç”ŸæˆBGEæ„å»ºè„šæœ¬: {script_path}")

if __name__ == "__main__":
    extract_esg_data()
